{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e2c23-bbcc-4f26-82f0-166e808557db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading phase picks from 2015-01-01T00:00:00.000000Z to 2016-01-01T00:00:00.000000Z...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import obspy\n",
    "import pandas as pd\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.header import FDSNNoDataException\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def split_time_range(start_time, end_time, interval_days=365):\n",
    "    \"\"\"\n",
    "    Splits a time range into smaller intervals.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    start_time : UTCDateTime\n",
    "        Start of the time range.\n",
    "    end_time : UTCDateTime\n",
    "        End of the time range.\n",
    "    interval_days : int, optional\n",
    "        Length of each interval in days (default: 365).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list of tuple\n",
    "        List of (start, end) pairs for each interval.\n",
    "    \"\"\"\n",
    "    intervals = []\n",
    "    current_start = start_time\n",
    "    while current_start < end_time:\n",
    "        current_end = min(current_start + interval_days * 24 * 3600, end_time)\n",
    "        intervals.append((current_start, current_end))\n",
    "        current_start = current_end\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def preprocess_phase(phase):\n",
    "    \"\"\"\n",
    "    Preprocess phase hint to classify into P or S wave categories\n",
    "\n",
    "    Parameters:\n",
    "    phase: str, phase hint from picks\n",
    "\n",
    "    Returns:\n",
    "    str: \"P\" or \"S\" or None if unclassified\n",
    "    \"\"\"\n",
    "    # Lowercase untuk konsistensi\n",
    "    phase = phase.lower()\n",
    "\n",
    "    # Daftar fase yang termasuk gelombang P\n",
    "    p_phases = [\"p\", \"pp\", \"pg\", \"pn\", \"pb\", \"pdiff\", \"pkp\", \"pkikp\", \"pp\"]\n",
    "\n",
    "    # Daftar fase yang termasuk gelombang S\n",
    "    s_phases = [\"s\", \"ss\", \"sg\", \"sn\", \"sb\", \"sdiff\", \"sks\", \"skiks\", \"ss\"]\n",
    "\n",
    "    if any(phase.startswith(p) for p in p_phases):\n",
    "        return \"P\"\n",
    "    elif any(phase.startswith(s) for s in s_phases):\n",
    "        return \"S\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_phase_picks(\n",
    "    start_time, end_time, station_code=None, evaluation_mode=\"all\", retry_count=3\n",
    "):\n",
    "    \"\"\"\n",
    "    Download phase picks with improved error handling and retries, with evaluation mode filtering.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    start_time : UTCDateTime\n",
    "        Start time for retrieving data.\n",
    "    end_time : UTCDateTime\n",
    "        End time for retrieving data.\n",
    "    station_code : str, optional\n",
    "        Code of the seismic station to filter picks (default: None, includes all stations).\n",
    "    evaluation_mode : str, optional\n",
    "        Filter picks by evaluation mode. Can be \"manual\", \"automatic\", or \"all\" (default: \"all\").\n",
    "    retry_count : int, optional\n",
    "        Number of retry attempts in case of errors (default: 3).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing picks information, filtered by the specified evaluation mode.\n",
    "        Returns None if no data is available.\n",
    "    \"\"\"\n",
    "    client = Client(\"GFZ\")\n",
    "\n",
    "    minlat = -11.0\n",
    "    maxlat = 6.0\n",
    "    minlon = 95.0\n",
    "    maxlon = 141.0\n",
    "\n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            catalog = client.get_events(\n",
    "                starttime=start_time,\n",
    "                endtime=end_time,\n",
    "                minlatitude=minlat,\n",
    "                maxlatitude=maxlat,\n",
    "                minlongitude=minlon,\n",
    "                maxlongitude=maxlon,\n",
    "                includearrivals=True,\n",
    "            )\n",
    "\n",
    "            picks_data = []\n",
    "            for event in catalog:\n",
    "                origin = event.preferred_origin() or event.origins[0]\n",
    "\n",
    "                for pick in event.picks:\n",
    "                    if station_code and pick.waveform_id.station_code != station_code:\n",
    "                        continue\n",
    "\n",
    "                    processed_phase = preprocess_phase(pick.phase_hint)\n",
    "                    if processed_phase:  # Only save if phase is classified\n",
    "                        if (\n",
    "                            evaluation_mode != \"all\"\n",
    "                            and pick.evaluation_mode != evaluation_mode\n",
    "                        ):\n",
    "                            continue  # Skip picks that don't match the specified mode\n",
    "\n",
    "                        pick_data = {\n",
    "                            \"event_id\": str(event.resource_id),\n",
    "                            \"event_time\": origin.time.datetime,\n",
    "                            \"event_latitude\": origin.latitude,\n",
    "                            \"event_longitude\": origin.longitude,\n",
    "                            \"event_depth\": origin.depth,\n",
    "                            \"station\": pick.waveform_id.station_code,\n",
    "                            \"network\": pick.waveform_id.network_code,\n",
    "                            \"channel\": pick.waveform_id.channel_code,\n",
    "                            \"phase\": processed_phase,  # Use processed phase\n",
    "                            \"original_phase\": pick.phase_hint,  # Save original phase\n",
    "                            \"pick_time\": pick.time.datetime,\n",
    "                            \"evaluation_mode\": pick.evaluation_mode,\n",
    "                            \"evaluation_status\": pick.evaluation_status,\n",
    "                        }\n",
    "                        picks_data.append(pick_data)\n",
    "\n",
    "            return pd.DataFrame(picks_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt < retry_count - 1:\n",
    "                print(f\"Attempt {attempt + 1} failed, retrying after 5 seconds...\")\n",
    "            else:\n",
    "                print(f\"Failed to get picks after {retry_count} attempts: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "\n",
    "def create_phase_labels(picks_df, waveform_stream, window_start, window_length):\n",
    "    \"\"\"\n",
    "    Create phase labels for a waveform window\n",
    "\n",
    "    Parameters:\n",
    "    picks_df: DataFrame containing picks\n",
    "    waveform_stream: ObsPy Stream object\n",
    "    window_start: UTCDateTime, start time of window\n",
    "    window_length: float, length of window in seconds\n",
    "\n",
    "    Returns:\n",
    "    numpy array of labels\n",
    "    \"\"\"\n",
    "    window_end = window_start + window_length\n",
    "\n",
    "    # Filter picks for this time window\n",
    "    window_picks = picks_df[\n",
    "        (picks_df.pick_time >= window_start) & (picks_df.pick_time <= window_end)\n",
    "    ]\n",
    "\n",
    "    # Create label array (sampling rate matches waveform)\n",
    "    sampling_rate = waveform_stream[0].stats.sampling_rate\n",
    "    n_samples = int(window_length * sampling_rate)\n",
    "\n",
    "    # Initialize labels arrays (0 = no pick, 1 = pick)\n",
    "    p_labels = np.zeros(n_samples)\n",
    "    s_labels = np.zeros(n_samples)\n",
    "\n",
    "    # Fill in picks\n",
    "    for _, pick in window_picks.iterrows():\n",
    "        # Calculate sample index for this pick\n",
    "        pick_sample = int((pick.pick_time - window_start) * sampling_rate)\n",
    "\n",
    "        if pick_sample >= 0 and pick_sample < n_samples:\n",
    "            if pick.phase == \"P\":\n",
    "                p_labels[pick_sample] = 1\n",
    "            elif pick.phase == \"S\":\n",
    "                s_labels[pick_sample] = 1\n",
    "\n",
    "    return np.vstack([p_labels, s_labels])\n",
    "\n",
    "\n",
    "def preprocess_waveform(event_stream, resample_rate=None):\n",
    "    \"\"\"\n",
    "    Preprocess waveform data to ensure consistent shape across components and optional resampling.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    event_stream : ObsPy Stream object\n",
    "        Waveform stream for an event.\n",
    "    resample_rate : float, optional\n",
    "        Target sampling rate in Hz for resampling (default: None, no resampling).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Array of waveform data with shape (3, n_samples) or None if preprocessing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if all components have the same sampling rate\n",
    "        sampling_rates = [tr.stats.sampling_rate for tr in event_stream]\n",
    "        if len(set(sampling_rates)) != 1:\n",
    "            print(\"Inconsistent sampling rates found\")\n",
    "            return None\n",
    "\n",
    "        # Resample if a target rate is specified\n",
    "        if resample_rate:\n",
    "            event_stream.resample(sampling_rate=resample_rate)\n",
    "\n",
    "        # Get lengths of all traces\n",
    "        lengths = [len(tr.data) for tr in event_stream]\n",
    "        if len(set(lengths)) != 1:\n",
    "            print(f\"Inconsistent trace lengths found: {lengths}\")\n",
    "            # Use shortest length\n",
    "            min_length = min(lengths)\n",
    "            for tr in event_stream:\n",
    "                tr.data = tr.data[:min_length]\n",
    "\n",
    "        # Convert to numpy array\n",
    "        waveform_data = np.array([tr.data for tr in event_stream])\n",
    "\n",
    "        # Check final shape\n",
    "        if waveform_data.shape[0] != 3:\n",
    "            print(f\"Unexpected number of components: {waveform_data.shape[0]}\")\n",
    "            return None\n",
    "\n",
    "        return waveform_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing waveform: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def prepare_dataset_with_labels(\n",
    "    station_code,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    pre_event_time=30,\n",
    "    window_length=120,\n",
    "    evaluation_mode=\"all\",\n",
    "    resample_rate=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares a dataset of waveform data and corresponding phase labels for a specific seismic station.\n",
    "\n",
    "    This function retrieves seismic waveform data and phase picks from the GFZ (GEOFON) client\n",
    "    for a given station and time range. The data is processed into a consistent format suitable\n",
    "    for machine learning applications. Each event is represented by waveform data (`X`) and\n",
    "    corresponding phase labels (`y`), indicating the presence of P and S phases within a specified\n",
    "    time window.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    station_code : str\n",
    "        Code of the seismic station (e.g., \"BBJI\").\n",
    "    start_time : UTCDateTime\n",
    "        Start time for retrieving data (inclusive).\n",
    "    end_time : UTCDateTime\n",
    "        End time for retrieving data (exclusive).\n",
    "    pre_event_time : float, optional\n",
    "        Time in seconds to include before the event time in the waveform window (default: 30).\n",
    "    window_length : float, optional\n",
    "        Total length of the waveform window in seconds (default: 120).\n",
    "    evaluation_mode : str, optional\n",
    "        Filter phase picks by evaluation mode (default: \"all\").\n",
    "    resample_rate : float, optional\n",
    "        Target sampling rate in Hz for resampling (default: None, no resampling).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple `(X, y)` where:\n",
    "        - `X` : numpy.ndarray\n",
    "            Array of waveform data with shape `(n_events, 3, n_samples)`, where:\n",
    "            - `n_events` : Number of valid seismic events.\n",
    "            - `3` : Waveform components (Z, N, E).\n",
    "            - `n_samples` : Number of samples in each waveform, determined by `window_length` and sampling rate.\n",
    "        - `y` : numpy.ndarray\n",
    "            Array of phase labels with shape `(n_events, 2, n_samples)`, where:\n",
    "            - `2` : Label dimensions for P (index 0) and S (index 1) phases.\n",
    "            - `n_samples` : Number of samples in each label array.\n",
    "        Returns `(None, None)` if no valid waveform or label data is found.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> from obspy import UTCDateTime\n",
    "    >>> X, y = prepare_dataset_with_labels(\n",
    "    ...     station_code=\"BBJI\",\n",
    "    ...     start_time=UTCDateTime(\"2023-01-01\"),\n",
    "    ...     end_time=UTCDateTime(\"2023-01-02\"),\n",
    "    ...     pre_event_time=60,\n",
    "    ...     window_length=600\n",
    "    ... )\n",
    "    >>> print(X.shape)  # (n_events, 3, n_samples)\n",
    "    >>> print(y.shape)  # (n_events, 2, n_samples)\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - Waveform data is truncated to ensure consistency across components.\n",
    "    - Labels are created by aligning phase picks (P and S) to the waveform samples within the time window.\n",
    "    - The function handles errors such as missing data or inconsistent waveform lengths.\n",
    "\n",
    "    \"\"\"\n",
    "    client = Client(\"GFZ\")\n",
    "\n",
    "    try:\n",
    "        # First check if data is available\n",
    "        st = client.get_waveforms(\n",
    "            network=\"GE\",\n",
    "            station=station_code,\n",
    "            location=\"*\",\n",
    "            channel=\"BH*\",\n",
    "            starttime=start_time,\n",
    "            endtime=start_time + 3600,  # Check first hour only\n",
    "            attach_response=False,\n",
    "        )\n",
    "    except FDSNNoDataException:\n",
    "        print(f\"No waveform data available for station {station_code}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking data availability for {station_code}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "    # Get picks for this station\n",
    "    picks_df = get_phase_picks(\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        station_code=station_code,\n",
    "        evaluation_mode=evaluation_mode,\n",
    "    )\n",
    "\n",
    "    if picks_df is None or len(picks_df) == 0:\n",
    "        print(f\"No picks found for station {station_code}\")\n",
    "        return None, None\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Process each event\n",
    "    for event_time in picks_df.event_time.unique():\n",
    "        try:\n",
    "            window_start = UTCDateTime(event_time) - pre_event_time\n",
    "            window_end = window_start + window_length\n",
    "\n",
    "            try:\n",
    "                event_stream = client.get_waveforms(\n",
    "                    network=\"GE\",\n",
    "                    station=station_code,\n",
    "                    location=\"*\",\n",
    "                    channel=\"BH*\",\n",
    "                    starttime=window_start,\n",
    "                    endtime=window_end,\n",
    "                )\n",
    "\n",
    "                if len(event_stream) == 3:\n",
    "                    # Preprocess waveform data\n",
    "                    waveform_data = preprocess_waveform(\n",
    "                        event_stream, resample_rate=resample_rate\n",
    "                    )\n",
    "                    if waveform_data is not None:\n",
    "                        event_picks = picks_df[picks_df.event_time == event_time]\n",
    "\n",
    "                        # Create labels\n",
    "                        n_samples = len(waveform_data[0])\n",
    "                        labels = np.zeros((2, n_samples))\n",
    "\n",
    "                        for _, pick in event_picks.iterrows():\n",
    "                            pick_time = UTCDateTime(pick.pick_time)\n",
    "                            if window_start <= pick_time <= window_end:\n",
    "                                idx = int(\n",
    "                                    (pick_time - window_start)\n",
    "                                    * event_stream[0].stats.sampling_rate\n",
    "                                )\n",
    "                                if idx < n_samples:\n",
    "                                    processed_phase = preprocess_phase(pick.phase)\n",
    "                                    if processed_phase == \"P\":\n",
    "                                        labels[0, idx] = 1\n",
    "                                    elif processed_phase == \"S\":\n",
    "                                        labels[1, idx] = 1\n",
    "\n",
    "                        X.append(waveform_data)\n",
    "                        y.append(labels)\n",
    "\n",
    "            except FDSNNoDataException:\n",
    "                continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event at {event_time}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if len(X) > 0:\n",
    "        return np.array(X), np.array(y)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def get_ge_stations():\n",
    "    \"\"\"\n",
    "    Returns dictionary of GE network stations in Indonesia\n",
    "    \"\"\"\n",
    "    stations = {\n",
    "        \"BBJI\": {\"name\": \"Bungbulang, Garut, Java\"},\n",
    "        \"CISI\": {\"name\": \"Cisomped, Java\"},\n",
    "        \"GSI\": {\"name\": \"Gunungsitoli, Nias\"},\n",
    "        \"BKB\": {\"name\": \"Balikpapan, Kalimantan\"},\n",
    "        \"BKNI\": {\"name\": \"Bangkinang, Sumatra\"},\n",
    "        \"BNDI\": {\"name\": \"Bandaneira, Indonesia\"},\n",
    "        \"FAKI\": {\"name\": \"Fak Fak, Irian Jaya\"},\n",
    "        \"GENI\": {\"name\": \"Genyem, Irian Jaya\"},\n",
    "        \"JAGI\": {\"name\": \"Jajag, Java\"},\n",
    "        \"LHMI\": {\"name\": \"Lhokseumawe, Sumatra\"},\n",
    "        \"LUWI\": {\"name\": \"Luwuk, Sulawesi\"},\n",
    "        \"MMRI\": {\"name\": \"Maumere, Flores\"},\n",
    "        \"MNAI\": {\"name\": \"Manna, Sumatra\"},\n",
    "        \"PLAI\": {\"name\": \"Plampang, Sumbawa\"},\n",
    "        \"PMBI\": {\"name\": \"Palembang, Sumatra\"},\n",
    "        \"PMBT\": {\"name\": \"Palembang, Sumatra\"},\n",
    "        \"SANI\": {\"name\": \"Sanana, Moluccas\"},\n",
    "        \"SAUI\": {\"name\": \"Saumlaki, Tanimbar\"},\n",
    "        \"SMRI\": {\"name\": \"Semarang, Java\"},\n",
    "        \"SOEI\": {\"name\": \"Soe, Timor\"},\n",
    "        \"TNTI\": {\"name\": \"Ternate, Indonesia\"},\n",
    "        \"TOLI\": {\"name\": \"Tolitoli, Sulawesi\"},\n",
    "        \"TOLI2\": {\"name\": \"Tolitoli, Sulawesi\"},\n",
    "        \"UGM\": {\"name\": \"Wanagama, Indonesia\"},\n",
    "        \"YOGI\": {\"name\": \"Yogyakarta, Java\"},\n",
    "    }\n",
    "    return stations\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set time period\n",
    "    start_time = UTCDateTime(\"2015-01-01\")\n",
    "    end_time = UTCDateTime(\"2024-01-01\")\n",
    "    EVALUATION_MODE = \"manual\"\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = \"seismic_data\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Split the time range into intervals\n",
    "    intervals = split_time_range(start_time, end_time, interval_days=365)\n",
    "    all_picks = []\n",
    "\n",
    "    for interval_start, interval_end in intervals:\n",
    "        print(f\"Downloading phase picks from {interval_start} to {interval_end}...\")\n",
    "        picks_df = get_phase_picks(\n",
    "            interval_start, interval_end, evaluation_mode=EVALUATION_MODE\n",
    "        )\n",
    "\n",
    "        if picks_df is not None and not picks_df.empty:\n",
    "            print(\n",
    "                f\"Found {len(picks_df)} picks for interval {interval_start} to {interval_end}\"\n",
    "            )\n",
    "            all_picks.append(picks_df)\n",
    "\n",
    "    # Combine all picks into one DataFrame\n",
    "    if all_picks:\n",
    "        picks_df = pd.concat(all_picks, ignore_index=True)\n",
    "        print(f\"Total picks collected: {len(picks_df)}\")\n",
    "\n",
    "        # Save all picks to a CSV file\n",
    "        picks_df.to_csv(os.path.join(output_dir, \"all_picks.csv\"), index=False)\n",
    "\n",
    "        # Get list of stations\n",
    "        stations = get_ge_stations()\n",
    "\n",
    "        # Process each station\n",
    "        for station_code in tqdm(stations.keys(), desc=\"Processing stations\"):\n",
    "            try:\n",
    "                print(\n",
    "                    f\"\\nProcessing station {station_code} ({stations[station_code]['name']})...\"\n",
    "                )\n",
    "\n",
    "                # Prepare dataset for this station\n",
    "                X, y = prepare_dataset_with_labels(\n",
    "                    station_code=station_code,\n",
    "                    start_time=start_time,\n",
    "                    end_time=end_time,\n",
    "                    pre_event_time=60,\n",
    "                    window_length=600,\n",
    "                    evaluation_mode=EVALUATION_MODE,\n",
    "                    resample_rate=100.0,  # Resample ke 100 Hz\n",
    "                )\n",
    "\n",
    "                if X is not None and len(X) > 0:\n",
    "                    # Create station-specific directory\n",
    "                    station_dir = os.path.join(output_dir, station_code)\n",
    "                    if not os.path.exists(station_dir):\n",
    "                        os.makedirs(station_dir)\n",
    "\n",
    "                    # Save datasets\n",
    "                    print(f\"Saving dataset with {len(X)} samples\")\n",
    "                    print(f\"Waveform shape: {X.shape}\")\n",
    "                    print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "                    np.save(os.path.join(station_dir, f\"waveforms.npy\"), X)\n",
    "                    np.save(os.path.join(station_dir, f\"labels.npy\"), y)\n",
    "\n",
    "                    # Save station-specific picks\n",
    "                    station_picks = picks_df[picks_df.station == station_code]\n",
    "                    station_picks.to_csv(\n",
    "                        os.path.join(station_dir, f\"picks.csv\"), index=False\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    print(f\"No valid data found for station {station_code}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing station {station_code}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Data saved in directory: {output_dir}\")\n",
    "    else:\n",
    "        print(\"No picks found for the specified time range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f1cbe-5c76-42b9-bbee-9130afb52afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find data with phase S in picks_df\n",
    "picks_df[picks_df[\"phase\"] == \"S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea0cf50-c01a-427b-bfdd-9e53fd4c99e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (earthquake-download)",
   "language": "python",
   "name": "earthquake-download"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
